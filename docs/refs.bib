@inproceedings{JakobiDingEtAl2025MultipleyeCorpus,
    author = {Jakobi, Deborah Noemie and Stegenwallner-Schütz, Maja and Hollenstein, Nora and Ding, Cui and Kaspere, Ramune and Mati\'{c} \v{S}kori\'{c}, Ana and Pavlinusic Vilus, Eva and Frank, Stefan and M\"{u}ller, Marie-Luise and Jensen de L\'{o}pez, Kristine M and Kharlamov, Nik and B. S\o{}ndergaard Knudsen, Hanne and Berzak, Yevgeni and Lion, Ella and Sekerina, Irina A. and Acarturk, Cengiz and Ansari, Mohd Faizan and Harezlak, Katarzyna and Kasprowski, Pawel and Bautista, Ana and Beinborn, Lisa and Bondar, Anna and Boznou, Antonia and Bradshaw, Leah and Hofmann, Jana Mara and Krosness, Thyra and Soliva, Not Battesta and \c{C}epani, Anila and Cergol, Kristina and Do\v{s}en, Ana and Palmovic, Marijan and \c{C}erpja, Adelina and Chirino, Dal\'{i} and Chrom\'{y}, Jan and Demberg, Vera and \v{S}krjanec, Iza and Deniz, Nazik Din\c{c}topal and Fajardo, Dr. Inmaculada and Gim\'{e}nez-Salvador, Mariola and M\'{i}nguez-L\'{o}pez, Xavier and Filip, Maro\v{s} and Freibergs, Zigmunds and Gomes, J\'{e}ssica and Janeiro, Andreia and Luegi, Paula and Ver\'{i}ssimo, Jo\~{a}o and Gramatikov, Sasho and Hasenäcker, Jana and Haveriku, Alba and Kote, Nelda and Kamal, Muhammad M. and Kundefineddzierska, Hanna and Klimek-Jankowska, Dorota and Kosutar, Sara and Krakowczyk, Daniel G. and Krejtz, Izabela and \L{}ockiewicz, Marta and L\~{o}o, Kaidi and Motiej\={u}nienundefined, Jurgita and Nasir, Jamal A. and Nederg\r{a}rd, Johanne Sofie Krog and \"{O}zkan, Ay\c{s}eg\"{u}l and Preininger, Mikul\'{a}\v{s} and Pung\u{a}, Loredana and Reich, David Robert and Tschirner, Chiara and Rot, \v{S}pela and Säuberli, Andreas and Sol\'{e}-Casals, Jordi and Strati, Ekaterina and Svoboda, Igor and Trandafili, Evis and Varlokosta, Spyridoula and Vulchanova, Mila and Jäger, Lena A.},
    title = {MultiplEYE: Creating a multilingual eye-tracking-while-reading corpus},
    year = {2025},
    isbn = {9798400714870},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    doi = {10.1145/3715669.3726843},
    abstract = {Eye-tracking-while-reading data provide valuable insights across multiple disciplines, including psychology, linguistics, natural language processing, education, and human-computer interaction. Despite its potential, the availability of large, high-quality, multilingual datasets remains limited, hindering both foundational reading research and advancements in applications. The MultiplEYE project addresses this gap by establishing a large-scale, international eye-tracking data collection initiative. It aims to create a multilingual dataset of eye movements recorded during natural reading, balancing linguistic diversity, while ensuring methodological consistency for reliable cross-linguistic comparisons. The dataset spans numerous languages and follows strict procedural, documentation, and data pre-processing standards to enhance eye-tracking data transparency and reproducibility. A novel data-sharing framework, integrated with data quality reports, allows for selective data filtering based on research needs. Researchers and labs worldwide are invited to join the initiative. By establishing and promoting standardized practices and open data sharing, MultiplEYE facilitates interdisciplinary research and advances reading research and gaze-augmented applications.},
    booktitle = {Proceedings of the 2025 Symposium on Eye Tracking Research and Applications},
    articleno = {111},
    numpages = {11},
    keywords = {Eye-tracking, reading, psycholinguistics, multilingual, open science},
    series = {ETRA '25}
}

@inproceedings{Krakowczyk_pymovementsETRA2023,
    author = {Daniel G. Krakowczyk and David R. Reich and Jakob Chwastek and Assunta Süss and Paul Prasse and Deborah N. Jakobi and Oleksii Turuta and Paweł Kasprowski and Lena A. J{\"a}ger},
    title = {pymovements: {A} {P}ython package for eye movement data processing},
    booktitle = {Proceedings of the ACM Symposium on Eye-Tracking Reseccarch and Applications},
    series = {ETRA 2023},
    year = {2023},
    publisher = {ACM},
    note = {in press},
    doi = {https://doi.org/10.1145/3588015.3590134}
}

@inproceedings{KrakowczykReich2025MoreTheMerrier,
    author = {Krakowczyk, Daniel G. and Reich, David R. and Säuberli, Andreas and \v{S}krjanec, Iza and Cretton, Isabelle C. R. and Jakobi, Deborah N. and Nisioi, Sergiu and Prasse, Paul and Jäger, Lena A.},
    title = {The More the Merrier: Boost Your Dataset Visibility and Discover Eye-Tracking Datasets with pymovements},
    year = {2025},
    isbn = {9798400714870},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    doi = {10.1145/3715669.3726810},
    abstract = {Eye movement research is often obstructed by the time-consuming challenges of accessing and preprocessing datasets, diverting efforts from scientific discovery. Researchers often struggle with non-standardized data formats, incomplete metadata, and scattered dataset repositories. Moreover, visibility of tediously collected and curated datasets is hindered without central aggregators that reference these valuable works. pymovements addresses these shortcomings by providing researchers with a seamless way to announce, discover, download, and process published eye movement datasets. We encourage researchers to contribute their eye-tracking datasets to our library to increase their visibility and impact.},
    booktitle = {Proceedings of the 2025 Symposium on Eye Tracking Research and Applications},
    articleno = {63},
    numpages = {3},
    keywords = {eye-tracking, datasets, open source, Python},
    series = {ETRA '25}
}

@book{MultiplEYE_DSP_2024,
    title = {MultiplEYE Data Sharing Policy},
    publisher = {PsychArchives},
    doi = {10.23668/psycharchives.14137},
    institution = {PsychArchives},
    author = {Müller, Marie-Luise and Kasperė, Ramunė and Jakobi, Deborah and Bradshaw, Leah and Hollenstein, Nora and Jäger, Lena},
    year = {2024},
    month = {Feb}
}
