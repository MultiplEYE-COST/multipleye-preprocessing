{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4550fb59660f9687",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T10:53:32.883940Z",
     "start_time": "2025-12-19T10:53:32.873216Z"
    }
   },
   "outputs": [],
   "source": [
    "import preprocessing\n",
    "from preprocessing.data_collection.multipleye_data_collection import (\n",
    "    MultipleyeDataCollection,\n",
    ")\n",
    "from preprocessing.scripts.prepare_language_folder import prepare_language_folder\n",
    "from preprocessing import config\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f825917",
   "metadata": {},
   "source": [
    "## Pre-processing MultiplEYE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5698b0b8af11afc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T10:52:30.284526Z",
     "start_time": "2025-12-19T10:52:30.279268Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collection_name = \"MultiplEYE_SQ_CH_Zurich_1_2025\"\n",
    "# data_collection_name = 'MultiplEYE_SL_SI_Ljubljana_1_2025'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88153aa0df294b",
   "metadata": {},
   "source": [
    "If necessary, prepare the data folder by unzipping the downloaded files. Works only for MultiplEYE and MeRID data collections so far. Also, there might be some manual steps necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b9fc003d4cd6e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T10:52:37.225394Z",
     "start_time": "2025-12-19T10:52:37.215977Z"
    }
   },
   "outputs": [],
   "source": [
    "prepare_language_folder(data_collection_name)\n",
    "this_repo = Path().resolve()\n",
    "data_folder_path = this_repo / \"data\" / data_collection_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4be66b6bf5eca968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T10:53:00.471422Z",
     "start_time": "2025-12-19T10:52:40.735173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder test_sessions does not match the regex pattern \\d\\d\\d_SQ_CH_1_ET\\d. Not considered as session.\n",
      "Folder pilot_sessions does not match the regex pattern \\d\\d\\d_SQ_CH_1_ET\\d. Not considered as session.\n",
      "Folder x024_SQ_CH_1_ET1_start_after_trial_10 does not match the regex pattern \\d\\d\\d_SQ_CH_1_ET\\d. Not considered as session.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting EDF to ASC: 100%|██████████| 21/21 [00:00<00:00, 27490.76it/s]\n",
      "Preparing session 018_SQ_CH_1_ET1: 100%|██████████| 21/21 [00:19<00:00,  1.07it/s]                   \n"
     ]
    }
   ],
   "source": [
    "multipleye_sq = MultipleyeDataCollection.create_from_data_folder(data_folder_path)\n",
    "\n",
    "preprocessed_data_folder = this_repo / \"preprocessed_data\" / data_collection_name\n",
    "preprocessed_data_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a12700",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T10:53:04.584921Z",
     "start_time": "2025-12-19T10:53:04.563022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\tMultiplEYE_SQ_CH_Zurich_1_2025\n",
       "Dataset_type\tMultiplEYE\n",
       "Number_of_sessions\t21\n",
       "Number_of_pilots\t0\n",
       "Tested_language\tSQ\n",
       "Country\tCH\n",
       "Year\t2025\n",
       "Number of eye-tracking (ET) sessions per participant\t1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multipleye_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e126376b369ad88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T10:53:08.385673Z",
     "start_time": "2025-12-19T10:53:08.374051Z"
    }
   },
   "outputs": [],
   "source": [
    "sessions = [s for s in multipleye_sq]\n",
    "sess = sessions[0]\n",
    "idf = sess.session_identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b315969",
   "metadata": {},
   "source": [
    "## Creating Gaze Frame from ASCII File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a9a145d7dff987c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T10:53:35.895677Z",
     "start_time": "2025-12-19T10:53:35.884494Z"
    }
   },
   "outputs": [],
   "source": [
    "asc = sess.asc_path\n",
    "output_folder = preprocessed_data_folder / idf\n",
    "output_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9160755a0d7cf15e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T10:53:50.645875Z",
     "start_time": "2025-12-19T10:53:36.368750Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable Gaze object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m gaze, gaze_metadata = preprocessing.load_gaze_data(\n\u001b[32m      2\u001b[39m     asc_file=asc,\n\u001b[32m      3\u001b[39m     lab_config=sess.lab_config,\n\u001b[32m      4\u001b[39m     session_idf=idf,\n\u001b[32m      5\u001b[39m     trial_cols=config.TRIAL_COLS,\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: cannot unpack non-iterable Gaze object"
     ]
    }
   ],
   "source": [
    "gaze, gaze_metadata = preprocessing.load_gaze_data(\n",
    "    asc_file=asc,\n",
    "    lab_config=sess.lab_config,\n",
    "    session_idf=idf,\n",
    "    trial_cols=config.TRIAL_COLS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d4f367e477b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44b22e1651562",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.save_raw_data(output_folder / \"raw_data\", sess.session_identifier, gaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d0283d6c77481",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.pm_gaze_metadata = gaze_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557282e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.pm_gaze_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758867c",
   "metadata": {},
   "source": [
    "## Coordinate and Velocity Preprocessing\n",
    "\n",
    "Eye movements are recorded in screen pixel coordinates, which depend on stimulus size and monitor setup. To compare gaze behavior across participants, screens, or datasets, it is standard to convert pixel positions \n",
    "into **degrees of visual angle (dva)**. Next, we compute **gaze velocity**, which allows us to detect saccades and distinguish them from fixations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd1fb200ffa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.preprocess_gaze(gaze)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd7080",
   "metadata": {},
   "source": [
    "## Detect Events and Compute Their Properties\n",
    "\n",
    "Eye-tracking data are typically segmented into events, i.e. `fixations` and `saccades`. Fixations represent moments when the eyes remain relatively still, allowing visual information to be processed, while saccades are the rapid movements between fixations that reposition the gaze. Detecting these events and computing their properties, such as `dispersion`, fixation `duration`, saccade `amplitude`, and `peak velocity`, provides the foundation for analyzing visual behavior and understanding how participants explore a stimulus.\n",
    "\n",
    "### Fixations\n",
    "\n",
    "We can detect fixations by applying the `I-VT` or the `I-DT` method.\n",
    "\n",
    "The **I-VT (Velocity-Threshold Identification)** method distinguishes fixation and saccade points based on their point-to-point velocities. Each point is classified as a fixation if its velocity is below the specified threshold. Consecutive fixation points are then merged into a single fixation. A threshold of 20 degrees/second is commonly used as a default maximum value. Read more about [the IVT algorithm in the documentation](https://pymovements.readthedocs.io/en/stable/reference/api/pymovements.events.detection.ivt.html) \n",
    "\n",
    "The **I-DT (Dispersion-Threshold Identification)** method finds fixations by grouping consecutive points within a maximum separation (dispersion) threshold and a minimum duration threshold. The algorithm slides a moving window across the data: if the dispersion within the window is below the threshold, the window represents a fixation and is gradually expanded until the dispersion exceeds the threshold.\n",
    "Read more about [our implementation of the IDT method](https://pymovements.readthedocs.io/en/stable/reference/api/pymovements.events.detection.idt.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fbaeae",
   "metadata": {},
   "source": [
    "We use the `I-VT` algorithm with the following key deafault parameters:\n",
    "- `minimum duration`: 100 ms \n",
    "- `velocity threshold`: 20.0\n",
    "\n",
    "Such properties as `location`, containing the centroid coordinates of each fixation, and `dispersion` will also be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ceab85113558a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.detect_fixations(\n",
    "    gaze,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dda025c",
   "metadata": {},
   "source": [
    "### Saccades\n",
    "\n",
    "Saccades are rapid eye movements that shift the point of fixation from one location to another. We detect saccades (or micro-saccades) from the velocity sequence of gaze data using the [microsaccades algorithm](https://pymovements.readthedocs.io/en/stable/reference/api/pymovements.events.detection.microsaccades.html#pymovements.events.detection.microsaccades). This algorithm implements a noise-adaptive velocity threshold, meaning that the detection threshold automatically scales with the noise level of the velocity signal. Such properties as `amplitude` and `peak velocity` of the detected saccades will also be calcuated.\n",
    "\n",
    "The key default parameters are:\n",
    "- `threshold_factor`: Multiplier used to determine the velocity threshold relative to the noise level of the signal. The default value is 6. A higher factor makes the algorithm more conservative (detects fewer saccades), while a lower factor makes it more sensitive.\n",
    "- `minimum_duration`: Defines how long a velocity peak must persist to be classified as a saccade. The duration is expressed in the same units as timesteps. If no timesteps are provided, the value refers to the number of samples (default = 6), which corresponds to about 12 ms at a 500 Hz sampling rate. Shorter events are ignored as noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2aa495b59316a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.detect_saccades(\n",
    "    gaze,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfcd58b5c45bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df080ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze.events.frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebecf61feb495157",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.save_events_data(\n",
    "    output_folder / \"fixations\", sess.session_identifier, gaze\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df4d9d480ed587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.save_scanpaths(output_folder / \"scanpaths\", sess.session_identifier, gaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b574c97f6b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.map_fixations_to_aois(\n",
    "    gaze,\n",
    "    sess.stimuli,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3044a4335d59477",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.save_session_metadata(gaze, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e87dfa1cab33c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultipleyeDataCollection.create_session_overview(\n",
    "    sess.session_identifier, path=output_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2e3618",
   "metadata": {},
   "source": [
    "## The END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271528ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze.detect(\n",
    "    method=\"ivt\", velocity_threshold=20, eye=\"auto\", clear=False, name=\"fixation.ivt\"\n",
    ")\n",
    "# You can now see the detected fixations in the gaze.events DataFrame under the name \"fixation.ivt\"\n",
    "gaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd90391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4afd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaze.detect('microsaccades', minimum_duration=12)\n",
    "\n",
    "# gaze.events.frame.filter(pl.col(\"name\") == \"saccades\").head()\n",
    "\n",
    "# You can experiment with different minimum durations for saccade detection\n",
    "# for md in [0.1, 5, 10, 12, 20, 100]:\n",
    "#     gaze.detect(\"microsaccades\", minimum_duration=md)\n",
    "\n",
    "#     print(md, gaze.events.frame.filter(pl.col(\"name\") == \"saccade\").height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa1f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze.detect(\"microsaccades\", minimum_duration=12)\n",
    "gaze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ac5385",
   "metadata": {},
   "source": [
    "### Areas Of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b3566",
   "metadata": {},
   "source": [
    "### Loading AOI File into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe32141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymovements.stimulus.text import from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_chars_files_folder = \"data/MultiplEYE_SQ_CH_Zurich_1_2025/eye-tracking-sessions/data_piloting_stimuli_MultiplEYE_SQ_CH_Zurich_1_2025participant_id_1_to_5/aoi_stimuli_sq_ch_1/\"\n",
    "\n",
    "# concatenate all available AOI character files into one DataFrame\n",
    "# To make your combined AOI dataset match the temporal order of the gaze data,\n",
    "# you must concatenate AOIs in the same sequence as the participant saw them.\n",
    "\n",
    "# option without questions\n",
    "# aoi_chars_file = \"concatenated_aoi_no_questions.csv\"\n",
    "\n",
    "# option with questions\n",
    "aoi_chars_file = \"concatenated_aoi_all.csv\"\n",
    "\n",
    "stimulus = from_file(\n",
    "    aoi_path=aoi_chars_file,\n",
    "    aoi_column=\"char\",\n",
    "    start_x_column=\"top_left_x\",\n",
    "    start_y_column=\"top_left_y\",\n",
    "    width_column=\"width\",\n",
    "    height_column=\"height\",\n",
    "    page_column=\"page\",\n",
    ")\n",
    "\n",
    "stimulus.aois.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d356809",
   "metadata": {},
   "source": [
    "### Mapping Fixations to AOI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gaze.samples.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0770a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We map each gaze point to an aoi, considering the boundary still part of the area of interest.\n",
    "\n",
    "# explode the list column \"pixel\" into two numeric columns\n",
    "# drop rows with null values in either pixel_xr or pixel_yr\n",
    "\n",
    "gaze.samples = gaze.samples.with_columns(\n",
    "    [\n",
    "        pl.col(\"pixel\").list.get(0).alias(\"pixel_xr\"),\n",
    "        pl.col(\"pixel\").list.get(1).alias(\"pixel_yr\"),\n",
    "    ]\n",
    ").drop_nulls(subset=[\"pixel_xr\", \"pixel_yr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a920ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples?\n",
    "print(len(gaze.samples))\n",
    "\n",
    "# How many AOIs?\n",
    "print(stimulus.aois.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10baf024",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = gaze.samples.head(40000)\n",
    "gaze_small = gaze.clone()\n",
    "gaze_small.samples = subset\n",
    "gaze_small.map_to_aois(aoi_dataframe=stimulus, eye=\"auto\", gaze_type=\"pixel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916c08d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_small.samples.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a275edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_small.samples.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbce5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(\n",
    "    gaze_small.samples[\"pixel_xr\"], gaze_small.samples[\"pixel_yr\"], s=5, label=\"gaze\"\n",
    ")\n",
    "plt.scatter(\n",
    "    stimulus.aois[\"top_left_x\"], stimulus.aois[\"top_left_y\"], s=5, label=\"AOI top-left\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Extract all message events mentioning \"question\"\n",
    "question_msgs = [\n",
    "    (int(m[\"timestamp\"]), m[\"message\"])\n",
    "    for m in sessions[0][\"messages\"]\n",
    "    if \"question\" in m[\"message\"].lower()\n",
    "]\n",
    "\n",
    "# Find min/max gaze time\n",
    "gaze_min, gaze_max = gaze.samples[\"time\"].min(), gaze.samples[\"time\"].max()\n",
    "\n",
    "for ts, msg in question_msgs:\n",
    "    inside = gaze_min <= ts <= gaze_max\n",
    "    print(f\"{ts}: {'✅ inside gaze data' if inside else '❌ outside'}  | {msg}\")\n",
    "\n",
    "# tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1752360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaze.map_to_aois(\n",
    "#     aoi_dataframe=stimulus,\n",
    "#     eye=\"auto\",\n",
    "#     gaze_type=\"pixel\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b68d046a395db56",
   "metadata": {},
   "source": [
    "Step 1 pf peyepline: create the gaze frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9601fb7cbdc65563",
   "metadata": {},
   "source": [
    "\t-- data collection folder\n",
    "\t---- ...\n",
    "\t---- fixations\n",
    "\t---- saccades(?)\n",
    "\t---- reading_measures\n",
    "\t---- raw_data (i.e. gaze sample csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d89bcf62fe7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymovements_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
