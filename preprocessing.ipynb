{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import preprocessing\n",
    "from preprocessing.data_collection.multipleye_data_collection import (\n",
    "    MultipleyeDataCollection,\n",
    ")\n",
    "from preprocessing.scripts.prepare_language_folder import prepare_language_folder\n",
    "from preprocessing import constants\n",
    "\n",
    "from pathlib import Path"
   ],
   "id": "6ee0ab70c17cd279"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pre-processing MultiplEYE Data",
   "id": "240de2fa987ff005"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_collection_name = 'MultiplEYE_SQ_CH_Zurich_1_2025'\n",
    "# data_collection_name = 'MultiplEYE_SL_SI_Ljubljana_1_2025'"
   ],
   "id": "1d3f699ddbaab8c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If necessary, prepare the data folder by unzipping the downloaded files. Works only for MultiplEYE and MeRID data collections so far. Also, there might be some manual steps necessary.",
   "id": "ddfc7187fa5a4bd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "this_repo = Path().resolve()\n",
    "data_folder_path = this_repo / \"data\" / data_collection_name\n",
    "\n",
    "# MultipleyeDataCollection.create_from_data_folder(data_folder_path)\n"
   ],
   "id": "d534348b319be729"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "multipleye_sq = MultipleyeDataCollection.create_from_data_folder(data_folder_path)\n",
    "\n",
    "preprocessed_data_folder = this_repo / \"preprocessed_data\" / data_collection_name\n",
    "preprocessed_data_folder.mkdir(parents=True, exist_ok=True)"
   ],
   "id": "d74c223998c87faa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "multipleye_sq",
   "id": "9784701f06e5e812"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sessions = [s for s in multipleye_sq]\n",
    "sess = sessions[0]\n",
    "idf = sess.session_identifier"
   ],
   "id": "5e3690c7e9cb8723"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating Gaze Frame from ASCII File",
   "id": "b4bc5f4a71ec89f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "asc = sess.asc_path\n",
    "output_folder = preprocessed_data_folder / idf\n",
    "output_folder.mkdir(parents=True, exist_ok=True)"
   ],
   "id": "5f06260ed14328e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "gaze, gaze_metadata = preprocessing.load_gaze_data(\n",
    "    asc_file=asc,\n",
    "    lab_config=sess.lab_config,\n",
    "    session_idf=idf,\n",
    "    trial_cols=constants.TRIAL_COLS,\n",
    ")"
   ],
   "id": "e7130ff7e72570e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "preprocessing.save_raw_data(output_folder / \"raw_data\", sess.session_identifier, gaze)",
   "id": "7dcf9499c1c7d3db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Coordinate and Velocity Preprocessing\n",
    "\n",
    "Eye movements are recorded in screen pixel coordinates, which depend on stimulus size and monitor setup. To compare gaze behavior across participants, screens, or datasets, it is standard to convert pixel positions \n",
    "into **degrees of visual angle (dva)**. Next, we compute **gaze velocity**, which allows us to detect saccades and distinguish them from fixations."
   ],
   "id": "226b9c65f412600a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "preprocessing.preprocess_gaze(gaze)",
   "id": "91a81b9ff414112a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Detect Events and Compute Their Properties\n",
    "\n",
    "Eye-tracking data are typically segmented into events, i.e. `fixations` and `saccades`. Fixations represent moments when the eyes remain relatively still, allowing visual information to be processed, while saccades are the rapid movements between fixations that reposition the gaze. Detecting these events and computing their properties, such as `dispersion`, fixation `duration`, saccade `amplitude`, and `peak velocity`, provides the foundation for analyzing visual behavior and understanding how participants explore a stimulus.\n",
    "\n",
    "### Fixations\n",
    "\n",
    "We can detect fixations by applying the `I-VT` or the `I-DT` method.\n",
    "\n",
    "The **I-VT (Velocity-Threshold Identification)** method distinguishes fixation and saccade points based on their point-to-point velocities. Each point is classified as a fixation if its velocity is below the specified threshold. Consecutive fixation points are then merged into a single fixation. A threshold of 20 degrees/second is commonly used as a default maximum value. Read more about [the IVT algorithm in the documentation](https://pymovements.readthedocs.io/en/stable/reference/api/pymovements.events.detection.ivt.html) \n",
    "\n",
    "The **I-DT (Dispersion-Threshold Identification)** method finds fixations by grouping consecutive points within a maximum separation (dispersion) threshold and a minimum duration threshold. The algorithm slides a moving window across the data: if the dispersion within the window is below the threshold, the window represents a fixation and is gradually expanded until the dispersion exceeds the threshold.\n",
    "Read more about [our implementation of the IDT method](https://pymovements.readthedocs.io/en/stable/reference/api/pymovements.events.detection.idt.html)."
   ],
   "id": "a1802e2dcb080c8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We use the `I-VT` algorithm with the following key deafault parameters:\n",
    "- `minimum duration`: 100 ms \n",
    "- `velocity threshold`: 20.0\n",
    "\n",
    "Such properties as `location`, containing the centroid coordinates of each fixation, and `dispersion` will also be calculated."
   ],
   "id": "3cfc489c2bc9f90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "preprocessing.detect_fixations(\n",
    "    gaze,\n",
    ")"
   ],
   "id": "7a8392b95d02f007"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Saccades\n",
    "\n",
    "Saccades are rapid eye movements that shift the point of fixation from one location to another. We detect saccades (or micro-saccades) from the velocity sequence of gaze data using the [microsaccades algorithm](https://pymovements.readthedocs.io/en/stable/reference/api/pymovements.events.detection.microsaccades.html#pymovements.events.detection.microsaccades). This algorithm implements a noise-adaptive velocity threshold, meaning that the detection threshold automatically scales with the noise level of the velocity signal. Such properties as `amplitude` and `peak velocity` of the detected saccades will also be calcuated.\n",
    "\n",
    "The key default parameters are:\n",
    "- `threshold_factor`: Multiplier used to determine the velocity threshold relative to the noise level of the signal. The default value is 6. A higher factor makes the algorithm more conservative (detects fewer saccades), while a lower factor makes it more sensitive.\n",
    "- `minimum_duration`: Defines how long a velocity peak must persist to be classified as a saccade. The duration is expressed in the same units as timesteps. If no timesteps are provided, the value refers to the number of samples (default = 6), which corresponds to about 12 ms at a 500 Hz sampling rate. Shorter events are ignored as noise. "
   ],
   "id": "6b96caecb2464e1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "preprocessing.detect_saccades(\n",
    "    gaze,\n",
    ")"
   ],
   "id": "1c571ff85455abb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "preprocessing.map_fixations_to_aois(\n",
    "    gaze,\n",
    "    sess.stimuli,\n",
    ")"
   ],
   "id": "bd9f500e8dc9209"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "gaze.save(output_folder / 'preprocessed_gaze', save_events=True, save_samples=True, verbose=2)",
   "id": "11933bdf2bcd4539"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate Reading Measures",
   "id": "3419a834b871b58f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from preprocessing.metrics.words import all_words_from_aois, find_skipped_words\n",
    "from preprocessing.metrics.fixations import annotate_fixations\n",
    "from preprocessing.metrics.reading_measures import build_word_level_table\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "aois = sess.stimuli[4].text_stimulus.aois"
   ],
   "id": "936a73d81ab66e90"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fixation-based Metrics",
   "id": "ee76a238e93a75a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fixation_table = annotate_fixations(gaze.events.frame)\n",
    "fixation_table"
   ],
   "id": "a737df060543bc90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trial = \"trial_4\"\n",
    "page = \"page_1\"\n",
    "\n",
    "fix_tp = fixation_table.filter(\n",
    "    (pl.col('trial') == trial) & (pl.col('page') == page)\n",
    ")"
   ],
   "id": "433a7392aa0b6160"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "all_words = all_words_from_aois(aois, page)\n",
    "\n",
    "words_with_skip = find_skipped_words(all_words, fix_tp)"
   ],
   "id": "68dcb21e6d178ada"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "word_level_table = build_word_level_table(\n",
    "    words=words_with_skip.with_columns([\n",
    "        pl.lit(trial).alias(\"trial\"),\n",
    "        pl.lit(page).alias(\"page\"),\n",
    "    ]),\n",
    "    fix=fix_tp,\n",
    ")"
   ],
   "id": "ee353e8cb493e3f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "word_level_table",
   "id": "4a61a40a86399385"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Transition-based Metrics",
   "id": "e53f648cc75ad249"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## The END\n",
   "id": "8f17e16a21954145"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\t-- data collection folder\n",
    "\t---- ...\n",
    "\t---- fixations\n",
    "\t---- saccades(?)\n",
    "\t---- reading_measures\n",
    "\t---- raw_data (i.e. gaze sample csv)"
   ],
   "id": "24143b765b30ff44"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
