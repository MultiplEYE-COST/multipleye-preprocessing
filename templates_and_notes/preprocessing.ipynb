{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiplEYE preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"../data/pilot-hr-1-zh\")\n",
    "stim_dir = Path(\"../data/stimuli_MultiplEYE_HR_CH_Zurich_1_2025\")\n",
    "output_dir = Path(\"output\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## EDF to ASC\n",
    "\n",
    "Use the `edf2asc` binary from the [EyeLink Developers Kit](https://www.sr-research.com/support/thread-13.html) to convert EDF files to ASC files.\n",
    "\n",
    "Notes:\n",
    "- We probably can't distribute the binary due to licensing issues. (But we might be able to distribute a Docker image?)\n",
    "- There is already an [issue](https://github.com/aeye-lab/pymovements/issues/509) to integrate this into `pymovements`.\n",
    "- The `-input` option is unnecessary, but currently required by `parse_eyelink()` in `pymovements`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "edf = data_dir / \"ch1hr007.edf\"\n",
    "subprocess.run(\n",
    "    [\"./edf2asc\", edf, \"-input\", \"-ftime\", \"-p\", output_dir, \"-y\"],\n",
    "    shell=True,\n",
    "    check=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASC to sample-level CSV\n",
    "\n",
    "Convert the ASC files to CSV files (one for each page) where each row is a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse ASC file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import polars as pl\n",
    "import pymovements as pm\n",
    "\n",
    "# asc = output_dir / \"ch1hr007.asc\"\n",
    "asc = \"data/003_HR_HR_1_ET1/003hrhr1.asc\"\n",
    "\n",
    "data, metadata = pm.gaze.from_asc(\n",
    "    asc,\n",
    "    patterns=[\n",
    "        r\"start_recording_(?P<trial>(?:PRACTICE_)?trial_\\d+)_(?P<screen>.+)\",\n",
    "        r\"start_recording_(?P<trial>(?:PRACTICE_)?trial_\\d+)_(?P<screen>familiarity_rating_screen_\\d+|subject_difficulty_screen)\",\n",
    "        {\"pattern\": r\"stop_recording_\", \"column\": \"trial\", \"value\": None},\n",
    "        {\"pattern\": r\"stop_recording_\", \"column\": \"screen\", \"value\": None},\n",
    "        {\n",
    "            \"pattern\": r\"start_recording_(?:PRACTICE_)?trial_\\d+_page_\\d+\",\n",
    "            \"column\": \"activity\",\n",
    "            \"value\": \"reading\",\n",
    "        },\n",
    "        {\n",
    "            \"pattern\": r\"start_recording_(?:PRACTICE_)?trial_\\d+_question_\\d+\",\n",
    "            \"column\": \"activity\",\n",
    "            \"value\": \"question\",\n",
    "        },\n",
    "        {\n",
    "            \"pattern\": r\"start_recording_(?:PRACTICE_)?trial_\\d+_(familiarity_rating_screen_\\d+|subject_difficulty_screen)\",\n",
    "            \"column\": \"activity\",\n",
    "            \"value\": \"rating\",\n",
    "        },\n",
    "        {\"pattern\": r\"stop_recording_\", \"column\": \"activity\", \"value\": None},\n",
    "        {\n",
    "            \"pattern\": r\"start_recording_PRACTICE_trial_\",\n",
    "            \"column\": \"practice\",\n",
    "            \"value\": True,\n",
    "        },\n",
    "        {\n",
    "            \"pattern\": r\"start_recording_trial_\",\n",
    "            \"column\": \"practice\",\n",
    "            \"value\": False,\n",
    "        },\n",
    "        {\"pattern\": r\"stop_recording_\", \"column\": \"practice\", \"value\": None},\n",
    "    ],\n",
    ")\n",
    "data.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map trial numbers to stimulus IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_ids = {\n",
    "    \"PRACTICE_trial_1\": \"practice1\",\n",
    "    \"PRACTICE_trial_2\": \"practice2\",\n",
    "}\n",
    "with open(\"data/pilot-hr-1-zh/logfiles/completed_stimuli.csv\") as f:\n",
    "    # with open(data_dir / \"logfiles\" / \"completed_stimuli.csv\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for i, row in enumerate(reader):\n",
    "        stimulus_ids[f\"trial_{i + 1}\"] = f\"stimulus{row['stimulus_id']}\"\n",
    "\n",
    "df = data.frame.with_columns(pl.col(\"trial\").replace(stimulus_ids).alias(\"stimulus_id\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write separate CSVs for each page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unnest [x, y] pixel column into separate pixel_x and piyel_y columns. This is necessary because polars does not support nested values when exporting CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\n",
    "    [\n",
    "        pl.all().exclude(\"pixel\"),\n",
    "        pl.col(\"pixel\").list.get(0).alias(\"pixel_x\"),\n",
    "        pl.col(\"pixel\").list.get(1).alias(\"pixel_y\"),\n",
    "    ]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = output_dir / \"raw\"\n",
    "raw_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for stimulus_id in df[\"stimulus_id\"].unique():\n",
    "    if stimulus_id is not None:\n",
    "        stimulus_df = df.filter((pl.col(\"stimulus_id\") == stimulus_id))\n",
    "        stimulus_df = stimulus_df.select(\n",
    "            [\n",
    "                pl.col(\"time\"),\n",
    "                pl.col(\"screen\"),\n",
    "                pl.col(\"pixel_x\"),\n",
    "                pl.col(\"pixel_y\"),\n",
    "                pl.col(\"pupil\"),\n",
    "            ]\n",
    "        )\n",
    "        stimulus_df.write_csv(raw_dir / f\"S007_{stimulus_id}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⬇️ Everything from this point on would be part of the published preprocessing pipeline ⬇️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import pymovements as pm\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Multipleye(pm.DatasetDefinition):\n",
    "    name: str = \"Multipleye\"\n",
    "\n",
    "    filename_format: str = r\"S{subject_id:d}_{stimulus_id}.csv\"\n",
    "\n",
    "    filename_format_dtypes = {\n",
    "        \"subject_id\": int,\n",
    "        \"stimulus_id\": str,\n",
    "        \"screen\": str,\n",
    "    }\n",
    "\n",
    "    trial_columns: list[str] = field(\n",
    "        default_factory=lambda: [\"subject_id\", \"stimulus_id\", \"screen\"]\n",
    "    )\n",
    "\n",
    "    time_column: str = \"time\"\n",
    "\n",
    "    time_unit: str = \"ms\"\n",
    "\n",
    "    pixel_columns: list[str] = field(default_factory=lambda: [\"pixel_x\", \"pixel_y\"])\n",
    "\n",
    "\n",
    "# TODO: Read this from a metadata file\n",
    "experiment = pm.Experiment(\n",
    "    sampling_rate=2000,\n",
    "    screen_width_px=1275,\n",
    "    screen_height_px=916,\n",
    "    screen_width_cm=37,\n",
    "    screen_height_cm=28,\n",
    "    distance_cm=60,\n",
    ")\n",
    "\n",
    "dataset = pm.Dataset(Multipleye(experiment=experiment), \"output\")\n",
    "dataset.load()\n",
    "dataset.gaze = dataset.gaze[:1]  # To avoid OOM\n",
    "dataset.gaze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixation and saccade detection\n",
    "\n",
    "Notes:\n",
    "- `compute_event_properties()` uses a lot of memory (https://github.com/aeye-lab/pymovements/issues/753). It's currently not possible to run it on the entire dataset on any ol' laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savitzky-Golay filter as in https://doi.org/10.3758/BRM.42.1.188\n",
    "window_length = round(experiment.sampling_rate / 1000 * 50)  # 50 ms\n",
    "if window_length % 2 == 0:  # Must be odd\n",
    "    window_length += 1\n",
    "dataset.pix2deg().pos2vel(\n",
    "    method=\"savitzky_golay\", window_length=window_length, degree=2\n",
    ")\n",
    "dataset.detect(\"ivt\")\n",
    "dataset.compute_event_properties((\"location\", dict(position_column=\"pixel\")))\n",
    "# dataset.detect(\"fill\", name=\"saccade\")\n",
    "# dataset.detect(\"microsaccades\")\n",
    "dataset.events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "### Gaze plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import polars as pl\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "trial = 0\n",
    "screen = \"page_2\"\n",
    "\n",
    "gaze_df = (\n",
    "    dataset.gaze[trial]\n",
    "    .frame.select(\n",
    "        pl.col(\"screen\"),\n",
    "        pl.col(\"pixel\").list.get(0).alias(\"pixel_x\"),\n",
    "        pl.col(\"pixel\").list.get(1).alias(\"pixel_y\"),\n",
    "    )\n",
    "    .filter(pl.col(\"screen\") == screen)\n",
    ")\n",
    "\n",
    "event_df = (\n",
    "    dataset.events[trial]\n",
    "    .frame.filter(pl.col(\"name\") == \"fixation\")\n",
    "    .select(\n",
    "        pl.col(\"screen\"),\n",
    "        pl.col(\"duration\"),\n",
    "        pl.col(\"location\").list.get(0).alias(\"pixel_x\"),\n",
    "        pl.col(\"location\").list.get(1).alias(\"pixel_y\"),\n",
    "    )\n",
    "    .filter(pl.col(\"screen\") == screen)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "stimulus_image = PIL.Image.open(\n",
    "    f\"../data/stimuli_MultiplEYE_HR_CH_Zurich_1_2025/stimuli_images_hr_ch_1/enc_wikimoon_id13_{screen}_hr.png\"\n",
    ")\n",
    "ax.imshow(stimulus_image)\n",
    "plt.plot(\n",
    "    gaze_df[\"pixel_x\"], gaze_df[\"pixel_y\"], color=\"black\", linewidth=0.5, alpha=0.3\n",
    ")\n",
    "for row in event_df.iter_rows(named=True):\n",
    "    fixation = Circle(\n",
    "        (row[\"pixel_x\"], row[\"pixel_y\"]),\n",
    "        math.sqrt(row[\"duration\"]),\n",
    "        color=\"blue\",\n",
    "        fill=True,\n",
    "        alpha=0.5,\n",
    "        zorder=10,\n",
    "    )\n",
    "    ax.add_patch(fixation)\n",
    "ax.set_xlim((0, experiment.screen.width_px))\n",
    "ax.set_ylim((experiment.screen.height_px, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
