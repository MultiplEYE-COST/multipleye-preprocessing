{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# pEYEpline: Preprocessing of the MultiplEYE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Files that go to the MultiplEyeStore repository:\n",
    "\n",
    "\n",
    "- **Raw recordings:** Raw files without any formatting applied (in the original encoding). --> to be decided if these data should really be included (con: storage; pro: stage 0 is good to have, some messages in the original files will be lost in the first step of preprocessing.) **Filename** must contain: participantId, stimulusId, TrialId\n",
    "  \n",
    "- **Raw data:** one csv file per stimulus text and per reader containing the following columns: ScreenId (x,y) screen location in pixels, gaze event (fixation, saccade, NaN, blink), optionally pupil size. **Filename** must contain: participantId, stimulusId, TrialId\n",
    "\n",
    "- **Fixation data:** one csv file per stimulus text and per reader containing one fixation per line with the following columns: ScreenId, onset-time, offset-time, (x,y) screen location in pixels (mean and std), duration, etc. **Filename** must contain: participantId, stimulusId, TrialId\n",
    "\n",
    "- **Saccade data:** one csv file per stimulus text and per reader containing one saccade per line with the following columns: screenId, onset-time, offset-time, start (x,y) screen location in pixels, end (x,y) screen location in pixels, duration, amplitude in deg of visual angle, amplitude in chars, mean velocity, peak velocity. **Filename** must contain: participantId, stimulusId, TrialId\n",
    "\n",
    "- **Interest area files** word- and char-based interest area files (can be merged with data when loading it), contain line information. **Filename** must contain: participantId, stimulusId, TrialId\n",
    "\n",
    "- **Reading measures files**: one csv file per stimulus text and per reader containing reading measures, aois, screenIds. **Filename** must contain: participantId, stimulusId, TrialId\n",
    "\n",
    "- **Data quality reports**:\n",
    "  - **Trial-level data quality reports:** json; one file per stimulus text per participant. **Filename** must contain: ParticipantId, StimulusId, TrialId\n",
    "  - **Session-level data quality reports:** json; One file per session (participant). Contains data quality measures aggregated for all data from one sesseion.  **Filename** must contain: participantId, \n",
    "  - **Dataset-level data quality reports** json; One file per dataset\n",
    "\n",
    "- **Response accuracies and text difficulty and familiarity ratings:** one csv or json file for each stimulus containing itemId, recorded response (pressed key), response type {target, distractor a, distractor b, distractor c}, response accuracies and latencies for all questions (=items) and and the text difficulty and familiarity rating for this text. **Filename** must contain: participantId, stimulusId\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs:\n",
    "# generate data quality report for each session asap after the session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Stimulus texts preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set set-up-specific variable values; default values are set for DiLi lab, ZH\n",
    "eyetracker = \"eyelink\"\n",
    "# TODO add all relevant set-up specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "*Terminology*\n",
    "- output = {preprocessing, filter-criteria, repository}\n",
    "- raw_recordings: eyetracking recording files generated by the eyetracker converted to *human-readable pure text format* (ascii)\n",
    "- raw_files: eyetracking raw recordings (csv format) in device-unspecific format containing times stamps, and screen coordinates in pixels, and, optionally, pupil size and unit\n",
    "- quality_report_raw_asc: file containing data quality measures extracted from the raw_recordings asc files (csv); eye-tracker-unspecific format, eyetracker-specific contents (missing values for some devices); one file per participant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Eye movements preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Compute different representations of eye movements (raw samples, gaze event data, reading measures) and add relevant information (aois) and the various identifiers (textiId, screenId, trialId).\n",
    "\n",
    "**Generate one file per participant per text for all stages of preprocessing (raw, events, reading measures).**\n",
    "\n",
    "**Identifiers:**\n",
    "Encode textId, participantId, and trialId only in the filename;\n",
    "Add screenId to the data\n",
    "\n",
    "**Interest areas**\n",
    "For the raw and the evant data, aois (char-based and word-based) will be stored as separate files that need to be merged with the eye movement data via the gaze/aoi screen coordinates when loading the data. \n",
    "\n",
    "**Note:** implement this when adding multipleye to the pymovements library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Processing of eye-tracker-specific raw recording files (e.g., edf files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Eyetracker-specific recording files to human-readable format\n",
    "- eyetracker-specific step\n",
    "- input is eyetracker specific, output is still eyetracker-specific\n",
    "- only applicable if original eyetracking recording files are not human readable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eyetracker == \"eyelink\":\n",
    "    pass\n",
    "    # load edf files\n",
    "    # apply edf2asc\n",
    "    # input: all edf data files\n",
    "    # output:\n",
    "    # name: raw_recordings\n",
    "    # format: asc (eyetracker specific contents)\n",
    "    # goes to: preprocessing\n",
    "elif eyetracker == \"tobii\":\n",
    "    pass\n",
    "    # load raw_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Processing of eyetracker-specific human-readable raw recording files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "- Eyetracker-specific input\n",
    "- Output should be eyetracker-unspecific in format, but will contain missing values in some places depending on the device\n",
    "- Extract information that are directly written as meta-information into the recording file (information about calibration scores etc)\n",
    "- Only stimulus-independent metrics\n",
    "- No metrics that need to be calculated from the data samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### Blink extraction \n",
    "\n",
    "- only applicable if eyetracker provides blinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blink detection:\n",
    "# If provided by the eyetracker: extract blinks (times stamp and duration) and write to csv\n",
    "\n",
    "# Input: raw_recordings\n",
    "# Output:\n",
    "# name: blinks_eyetracker\n",
    "# format: csv\n",
    "# goes to: preprocessing (data quality reports, gaze events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### Extract data quality information from eyetracker-specific recording files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data quality report that contains information that the eyetracker writes as meta-data into the recording\n",
    "# TODO decide about the exact metrics\n",
    "# Preliminary list of values/information to extract\n",
    "# - Is the session complete? (all stimuli being completed and all questions answered); of not: how much is missing? (e.g., provide proportion completed in terms of screens and in terms of texts)\n",
    "# - Have all comprehension questions been answered? (if this information is available in raw recordings)\n",
    "# - Was calibration and validation performed at the beginning of the experiment? (scores?)\n",
    "# - Has validation performed before each text? extract validation scores before each text (if validation was followed by a calibration and then a second validation, use the scores from the second validation)\n",
    "# - Was a validation check  performed at the end of the recording? Extract validation scores.\n",
    "# - calibration scores, validation scores; when/how many calibrations were performed?\n",
    "# - when/to what extent has drift correction been performed? (timestamp, before which trial/item id? Was the drift corrected or only checked?\n",
    "# - What (if any) filter was applied for data recording?\n",
    "# - if blinks have been extracted (see above), compute proportion/frequency of blinks, and some measure reflecting their mean and std duration (or median)\n",
    "\n",
    "# Input: raw_recordings\n",
    "# Output:\n",
    "# name: quality_report_raw_asc\n",
    "# format: csv or json\n",
    "# goes to: preprocessing: session-level data quality reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Parsing of eyetracker-specific raw recording files to consistent eyetracker-unspecific csv files containing the raw samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "- Eytracker-specific input/code, output eyetracker-unspecific\n",
    "- Apply inclusion criteria: a given participant needs to have completed reading at least one entire text (practice texts do not count) and have answered the comprehension questions for that text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process raw recording files to csv with\n",
    "\n",
    "# Generate one file for each participant with the following columns: trialID, stimulusId, screenId, timestamp in ms, x-gaze coordinate in screen pixels, y-gaze coordinate in screen pixels, optional: pupil size, pupil size measurement unit (diameter, area...)\n",
    "# Ensure that the same coordinate system is used across devices/datasets\n",
    "# make sure to split data by stimulusId (=text) and screenid\n",
    "# Apply inclusion criterion: remove participants who have not completed at least one entire text plus the corresponding comprehension questions\n",
    "# merge multiple eyetracking files from one participant (only applicable if experiment was aborted and re-started)\n",
    "# handle any other inconsistencies (wrong participant IDs (caution: the id is in many files), aborted trials, missing data,....\n",
    "\n",
    "# Arguments: eyetracking device (format of raw_recordings)\n",
    "# Input: raw_recordings\n",
    "# Output:\n",
    "# name: raw_files\n",
    "# format: csv (consistent columns across devices; trialId, stimuulusId, screenId, x,y-screen px coords, optional column for pupil size); one file for each participant\n",
    "# goes to: preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Processing of raw samples (csv format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### Generate data quality measures from raw samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the following measures (preliminary list) from the raw eyetracking data:\n",
    "\n",
    "# duration of the recording (for each text or for each screen and total duration);\n",
    "# proportion of data loss\n",
    "\n",
    "# Input: raw_files\n",
    "# Output:\n",
    "# name: quality_report_raw\n",
    "# format: csv or json\n",
    "# goes to: repository, filter_criteria (possibly after merging with quality measures computed at the other stages of preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "#### Gaze event detection and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaze even detection\n",
    "# Compute gaze events and add them as additional column to the raw samples (saccade, fixation, blink, artifact/corrupt measurement)\n",
    "# Apply artifact detection, blink detection, saccade/fixation detection\n",
    "\n",
    "# Input: raw_files\n",
    "# Output:\n",
    "# name: gave_event_files\n",
    "# format: csv\n",
    "# goes to: preprocessing, repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fixation files\n",
    "# From raw samples classified as fixations, compute fixation features:\n",
    "\n",
    "# Preliminary list of fixation features:\n",
    "# start timestamp\n",
    "# end timestamp\n",
    "# duration\n",
    "# standard deviation\n",
    "# location (mean)\n",
    "\n",
    "# Input: gaze_event_files\n",
    "# Output:\n",
    "# name: fixation_files\n",
    "# format: csv files; one fixation file and one saccade file per participant and text)\n",
    "# goes to: preprocessing for adding aoi infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute saccade files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Processing of raw samples (csv format) and aoi files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Input is raw samples and aoi files (char-based or word-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "#### Add aoi information to raw samples\n",
    "- To be decided: Shall we share these files on the repository?\n",
    "    - Pro: maybe useful for some users who want to work on the raw data plus aoi info\n",
    "    - Con: Take a lot of space; these data can be easily generated by the user of MulitplEYE\n",
    "- (Potential) use cases of these data: plotting of raw data and aoi\n",
    "- Generation of Data quality report (next step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge aoi files with raw data (aoi as additional columns and NaNs)\n",
    "# Input: char-based or word-based aoi's\n",
    "# Output:\n",
    "# name: raw_files_aoi\n",
    "# format: csv\n",
    "# goes to:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "#### Generate stimulus-dependent quality measures from raw samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### Add aois to fixation files\n",
    "Input: fixation files, word-based and char-based aoi files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## Write trial-level data quality reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## Write session-level data quality reports\n",
    "Combine all session-level data quality reports that have been generated at the different steps of the pipeline into a single report (one file per session (=reader)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all readers combine quality reports from all texts into a single session (=reader)-level quality report\n",
    "\n",
    "# Inputs:\n",
    "# quality_report_raw_asc, quality_report_raw, TODO\n",
    "# Output:\n",
    "# name: session_level_quality_reports (one file per reader)\n",
    "# format: json\n",
    "# goes to: repository, filter-criteria, preprocessing (dataset-level data quality reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## Generate dataset-level data quality reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### Compute dataset-level data quality information from session-level data quality reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the session-level data quality measures to the dataset level\n",
    "# Input: session_level_quality_reports (one file per reader)\n",
    "# Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### Get dataset-level data quality information from meta-data documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read meta-data documentation, deviation form etc. TODO Which files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### Write dataset-level data quality report"
   ]
  },
  {
   "cell_type": "raw",
   "id": "46",
   "metadata": {},
   "source": [
    "Notes: \n",
    "Things that could be done (low priority): \n",
    "- Data quality reports for eye movements on comprehension questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "## Comprehension questions and difficulty/familiarity rating response processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the participant's response (pressed key) and target answer, compute response accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each participant and each text, write file with response behavior and text difficulty and familiarity ratings:**\n",
    "# one csv or json file for each stimulus containing itemId, recorded response (pressed key), response type {target, distractor a, distractor b, distractor c}, response accuracies and latencies for all questions (=items) and and the text difficulty and familiarity rating for this text. **Filename** must contain: participantId, stimulusId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
